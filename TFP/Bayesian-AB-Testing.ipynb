{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default_settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian A/B Testing\n",
    "\n",
    "A/B testing is a statistical design pattern for determining the difference of effectiveness between two different treatments. For example, a pharmaceutical company is interested in the effectiveness of drug A vs drug B. The company will test drug A on some fraction of their trials, and drug B on the other fraction (this fraction is often 1/2, but we will relax this assumption). After performing enough trials, the in-house statisticians sift through the data to determine which drug yielded better results.\n",
    "\n",
    "## A simple case\n",
    "As this is a hacker book, we'll continue with the web-dev example. For the moment, we will focus on the analysis of site A only. Assume that there is some true $0 \\lt p_A \\lt 1$ probability that users who, upon shown site A, eventually purchase from the site. This is the true effectiveness of site A. Currently, this quantity is unknown to us.\n",
    "\n",
    "Suppose site A was shown to $N$ people, and $n$ people purchased from the site. One might conclude hastily that $p_A = \\frac{n}{N}$. Unfortunately, the observed frequency $\\frac{n}{N}$ does not necessarily equal $p_A$ -- there is a difference between the observed frequency and the true frequency of an event. The true frequency can be interpreted as the probability of an event occurring. For example, the true frequency of rolling a 1 on a 6-sided die is $\\frac{1}{6}$. Knowing the true frequency of events like:\n",
    "\n",
    "- fraction of users who make purchases,\n",
    "- frequency of social attributes,\n",
    "- percent of internet users with cats etc.\n",
    "are common requests we ask of Nature. Unfortunately, often Nature hides the true frequency from us and we must *infer* it from observed data.\n",
    "\n",
    "The *observed frequency* is then the frequency we observe: say rolling the die 100 times you may observe 20 rolls of 1. The observed frequency, 0.2, differs from the true frequency, $\\frac{1}{6}$. We can use Bayesian statistics to infer probable values of the true frequency using an appropriate prior and observed data.\n",
    "\n",
    "With respect to our A/B example, we are interested in using what we know, $N$ (the total trials administered) and $n$ (the number of conversions), to estimate what $p_A$, the true frequency of buyers, might be.\n",
    "\n",
    "To setup a Bayesian model, we need to assign prior distributions to our unknown quantities. A priori, what do we think $p_A$ might be? For this example, we have no strong conviction about $p_A$, so for now, let's assume $p_A$ is uniform over $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_sess()\n",
    "\n",
    "# The parameters are the bounds of the Uniform.\n",
    "p = tfd.Uniform(low=0, high=1., name='p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had we had stronger beliefs, we could have expressed them in the prior above.\n",
    "\n",
    "For this example, consider $p_A = 0.05$, and $N = 1500$ users shown site A, and we will simulate whether the user made a purchase or not. To simulate this from $N$ trials, we will use a Bernoulli distribution: if  $X\\ \\sim \\text{Ber}(p)$, then $X$ is 1 with probability $p$ and 0 with probability $1 - p$. Of course, in practice we do not know $p_A$, but we will use it here to simulate the data. We can assume then that we can use the following generative model:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p \\,\\sim \\text{Uniform}[\\text{low}=0,\\text{high}=1) \\\\\n",
    "X\\,\\sim \\text{Bernoulli}(\\text{prob}=p) \\\\\n",
    "\\text{for }  i \\,= 1\\ldots N:\\text{# Users}  \\\\\n",
    " X_i\\,\\sim \\text{Bernoulli}(p_i)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of 1500 occurrences: [0 0 0 ... 0 0 0]\n",
      "(Remember: Python treats True == 1, and False == 0)\n",
      "Sum of (True == 1) Occurrences: 76\n"
     ]
    }
   ],
   "source": [
    "reset_sess()\n",
    "\n",
    "# set constants\n",
    "prob_true = 0.05 # remember, this is unknown\n",
    "N = 1500\n",
    "\n",
    "# Sample N Bernoulli random variables from Ber(0.05)\n",
    "# Each random variable has a 0.05 chance of being a 1.\n",
    "# This is the data-generation step\n",
    "\n",
    "occurrences = tfd.Bernoulli(probs=prob_true).sample(sample_shape=N, seed=6.45)\n",
    "\n",
    "[\n",
    "    occurrences_,\n",
    "    occurrences_sum_,\n",
    "    occurrences_mean_,\n",
    "] = evaluate([\n",
    "    occurrences,\n",
    "    tf.reduce_sum(occurrences),\n",
    "    tf.reduce_mean(tf.to_float(occurrences))\n",
    "])\n",
    "\n",
    "print('Array of {} occurrences:'.format(N), occurrences_)\n",
    "print('(Remember: Python treats True == 1, and False == 0)')\n",
    "print('Sum of (True == 1) Occurrences:', occurrences_sum_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed frequency is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the observed frequency in Group A? 0.05066666752099991\n",
      "Does this equal to the true frequency? False\n"
     ]
    }
   ],
   "source": [
    "# occurrences.mean is equal to n/N.\n",
    "print(\"what is the observed frequency in Group A? {}\".format(occurrences_mean_))\n",
    "print(\"Does this equal to the true frequency? {}\".format(occurrences_mean_ == prob_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine our Bernoulli distribution and our observed occurrences into a log probability function based on the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_log_prob(occurrences, prob_A):\n",
    "    \"\"\"Joint probability optimization function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    occurences: array-like, binary values \n",
    "        Observed frequency\n",
    "    prob_A: scalar\n",
    "        Probability of a 1 appearing.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Joint log probability optimization function.\n",
    "    \"\"\"\n",
    "    rv_prob_A = tfd.Uniform(low=0, high=1.)\n",
    "    \n",
    "    rv_occurrences = tfd.Bernoulli(probs=prob_A)\n",
    "    \n",
    "    return rv_prob_A.log_prob(prob_A) + tf.reduce_sum(rv_occurrences.log_prob(occurrences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of probabilistic inference is to find model parameters that may explain data you have observed. TFP performs probabilistic inference by evaluating the model parameters using a `joint_log_prob` function. The arguments to `joint_log_prob` are data and model parameters - for the model defined in the `joint_log_prob` function itself. The function returns the log of the joint probability that the model parameterized as such generated the observed data per the input arguments.\n",
    "\n",
    "All `joint_log_prob` functions have a common structure:\n",
    "1. The function takes a set of **inputs** to evaluate. Each input is either an observed value or a model parameter.\n",
    "2. The `joint_log_prob` function uses probability distribution to define a **model** for evaluating the inputs. These distributions measure the likelihood of the input values. (By convention, the distribution that measures the likelihood of the variable `foo` will be named `rv_foo` to note that it is a random variable). We use two types of distributions in `joint_log_prob` functions:\n",
    "    1. **Prior distributions** measure the likelihood of input values. A prior distribution never depends on an input value each prior distribution measures the likelihood of a single input value. Each unknown variable - one that has not been observed directly - needs a corresponding prior. Beliefs about which values could be reasonable determine the prior distribution. Choosing a prior can be tricky.\n",
    "    2. **Conditional distributions** measure the likelihood of an input value given other input values. Typically, the conditional distributions return the likelihood of observed data given the current guess of parameters in the model, *p*(observed_data | model_parameters).\n",
    "    3. Finally we calculate and return the **joint log probability** of the inputs. The joint log probability is the sum of the log probabilities from all the prior and conditional distributions. (We take the sum of log probabilities instead of multiplying the probabilities directly for reasons of numerical stability: floating point numers in computers cannot represent the very small values needed to calculate the joint log probability unless they are in log space). The sum of probabilities is actually an unnormalized density; although the total sum of probabilities over all possible inputs might not sum to one, the sum of probabiltiies is proportional to the true probability density. The proportional distribution is sufficient to estimate the distribution of likely inputs. \n",
    "    \n",
    "Let's map these tems onto the code above. In this example, the input values are the observed values in `occurrences` and the unknown value for `prob_A`. The `joint_log_prob` takes the current guess for `prob_A` and answers, how likely is the data if `prob_A` is the probability of `occurrences`. The answer depends on two distributions:\n",
    "\n",
    "1. The prior distribution, `rv_prob_A`, indicates how likely the current value of `prob_A` is by itself.\n",
    "2. The conditional distribution, `rv_occurrences`, indicates the likelihood of `occurrences` if `prob_A` were the probability for the Bernoulli distribution. \n",
    "\n",
    "The sum of the log of these probabiities is the joint log probability.\n",
    "\n",
    "The `joint_log_prob` is particularly useful in conjunction with the `tfp.mcmc` module. Markov chain Monte Carlo (MCMC) algorithms proceed by making educated guesses about the unknown input values and computing what the likelihood of this set of arguments is. By repeating this process many times, MCMC builds a distribution of likely parameters. Constructing this distribution is the goal of probabilistic inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps = 48000\n",
    "burnin = 25000\n",
    "leapfrog_steps = 2\n",
    "\n",
    "# Set the chain's start state.\n",
    "initial_chain_state = [\n",
    "    tf.reduce_mean(tf.to_float(occurrences))\n",
    "    * tf.ones([], dtype=tf.float32, name='init_prob_A')\n",
    "]\n",
    "\n",
    "# Since HMC operates over unconstrained space, we need to transform the \n",
    "# samples so they live in real space.\n",
    "unconstraining_bijectors = [\n",
    "    tfp.bijectors.Identity()\n",
    "]\n",
    "\n",
    "# Define a closure over our joint_log_prob\n",
    "# The closure marks it so the HMC doesn't try to change the 'occurrences' but instead determines the distributions\n",
    "# of other parameters that might generate the 'occurrences' we observed.\n",
    "unnormalized_posterior_log_prob = lambda *args: joint_log_prob(occurrences, *args)\n",
    "\n",
    "# Initialize the step size. (It will be automatically adapted.)\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "    step_size = tf.get_variable(name='step_size',\n",
    "                               initializer=tf.constant(0.5, dtype=tf.float32),\n",
    "                               trainable=False,\n",
    "                               use_resource=True)\n",
    "# Defining the HMC\n",
    "hmc = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "        num_leapfrog_steps=leapfrog_steps,\n",
    "        step_size=step_size,\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),\n",
    "        state_gradients_are_stopped=True),\n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "# Sampling from the chain.\n",
    "[\n",
    "    posterior_prob_A\n",
    "], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=number_of_steps,\n",
    "    num_burnin_steps=burnin,\n",
    "    current_state=initial_chain_state,\n",
    "    kernel=hmc)\n",
    "\n",
    "# Initialize any created variables.\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the TF graph to sample from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate: 0.6121458333333333\n"
     ]
    }
   ],
   "source": [
    "evaluate(init_g)\n",
    "evaluate(init_l)\n",
    "[\n",
    "    posterior_prob_A,\n",
    "    kernel_results_,\n",
    "] = evaluate([\n",
    "    posterior_prob_A,\n",
    "    kernel_results,\n",
    "])\n",
    "\n",
    "print('acceptance rate: {}'.format(\n",
    "    kernel_results_.inner_results.is_accepted.mean()))\n",
    "\n",
    "burned_prob_A_trace_ = posterior_prob_A[burnin:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
