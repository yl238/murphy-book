{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.14 A measure of correlation (normalized mutual information)\n",
    "(Source: (Cover and Thomas 1991, Q2.20).) Let $X$ and $Y$ be discrete random variables which are identically distributed (so $H(X) = H(Y))$ but not necessarily independent. Define\n",
    "\n",
    "$$\n",
    "r = 1-\\frac{H(Y|X)}{H(X)}\n",
    "$$\n",
    "\n",
    "* a) Show $r = \\frac{I(X, Y)}{H(X)}$\n",
    "* b) Show $0 \\le r \\le 1$\n",
    "* c) When is $r=0$?\n",
    "* d) When is $r=1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we are going to analyse the meaning of $r$, a function defined in terms of entropies. As the text hints, we should expect that $r$ behaves like a information theory correlation function. In other words, $r$ should be a normalized value that tells how dependent two random variables are from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "#### (a)\n",
    "We must show that $r=\\frac{I(X, Y)}{H(X)}$:\n",
    "\n",
    "$$\n",
    "    r = 1 - \\frac{H(Y|X)}{H(X)} = \\frac{H(X) - H(Y|X)}{H(X)} = \\frac{I(X, Y)}{H(X)}\n",
    "$$\n",
    "\n",
    "#### (b)\n",
    "\n",
    "$$\n",
    "H(p) = \\sum p(-\\log p)\\ge 0\n",
    "$$\n",
    "\n",
    "Using this, we can write\n",
    "\n",
    "$$\n",
    "\\frac{H(Y|X)}{H(X)} \\ge 0 \\implies 1- \\frac{H(Y|X)}{H(X)} \\le 1\n",
    "$$\n",
    "\n",
    "Also,\n",
    "\n",
    "$$\n",
    "I(X, Y) = H(X) - H(Y|X)\\ge 0 \\implies H(Y|X) \\le H(X) \\implies 1-\\frac{H(Y|X)}{H(X)} \\ge 0\n",
    "$$\n",
    "Thus $0\\le r \\le 1$\n",
    "\n",
    "#### (c)\n",
    "$$\n",
    "r = \\frac{I(X, Y)}{H(X)} = 0 \\iff I(X, Y) = 0\n",
    "$$\n",
    "\n",
    "#### (d)\n",
    "$r = 1 \\iff I(X, Y) = H(X).$ Which is the same thing as saying $r=1 \\iff H(Y|X) = 0$. Let's see what $H(Y|X) = 0$ means:\n",
    "\n",
    "\\begin{aligned}\n",
    "H(Y|X) = \\sum_xp(x)H(Y|X=x) & = \\sum_xp(x)\\sum_yp(y|x)(-\\log(p(y|x)) \\\\\n",
    "& = \\sum_x\\sum_y p(x)p(y|x)(-\\log(p(y|x))\n",
    "\\end{aligned}\n",
    "\n",
    "Observe that each term of the summation is non negative. Thus every term must be 0 in order for the above equation to be true. Thus $p(y|x)=0$ or $\\log p(y|x) = 0$. The second condition only happens when $p(y|x) = 1$. \n",
    "\n",
    "So $H(Y|X) = 0$ says to us that given $X$, we know exactly which $Y$ is going to occur. In other words, $Y = f(X)$. Since the problem is symmetrical, $f$ is invertible and we can also express this as $X = f^{-1}(X)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this section we study the parameter $r$ defined as $r=1-\\frac{H(Y|X)}{H(X)}$. We discovered it behaves very similarly to the classical correlation. Being more specific, we found out four things:\n",
    "\n",
    "1. $r$ is a ratio between mutual information and entropy, much like the classical correlation is a ratio between covariance and variances (Note that since we are assuming $H(X) = H(Y)$ then $r=\\frac{I(X,Y)}{\\sqrt{H(x)}\\sqrt{H(Y)}}$. \n",
    "2. The ratio is normalised (i.e. between 0 and 1)\n",
    "3. $r=0\\iff X$ and $Y$ are independent\n",
    "4. $r=1\\iff Y = f(X)$, where $f$ is invertible.\n",
    "\n",
    "Overall, we see that the parameter $r$ has the same goal as $\\rho$, but it is more general, because it uses entropies instead of covariances. The first advantage is that it captures linear and non-linear functions between $X$ and $Y$. The second advantage is that $r=0 \\implies X$ and $Y$ are independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
