{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.7 Bayesian analysis of the Poisson distribution\n",
    "In Exercise 3.6, we defined the Poisson distribution with rate $\\lambda$ and derived its MLE. Here we perform a conjugate Bayesian analysis.\n",
    "\n",
    "- a. Derive the posterior $p(\\lambda|D)$ assuming a conjugate prior $p(\\lambda) = \\mathrm{Ga}(\\lambda|a, b) \\propto \\lambda^{a-1}e^{-\\lambda b}$. Hint: the posterior is also a Gamma distribution.\n",
    "- b. What does the posterior mean tend to as $a \\rightarrow 0$ and $b \\rightarrow 0$? (Recall that the mean of a $\\mathrm{Ga}(a, b)$ distribution is $a/b$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "#### (a)\n",
    "Let $D = \\{x_i,\\ldots, x_n\\}$ be i.i.d samples from $\\mathrm{Poi}(x|\\lambda)$.\n",
    "\n",
    "The likelihood is \n",
    "\n",
    "$$\n",
    "p(D|\\lambda) = e^{-n\\lambda}\\frac{\\lambda^{\\sum_i x_i}}{\\prod_ix_i!}\n",
    "$$\n",
    "\n",
    "The prior is\n",
    "\n",
    "$$\n",
    "p(\\lambda) = \\mathrm{Ga}(a, b) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-\\lambda b}\n",
    "$$\n",
    "\n",
    "So the posterior is given by\n",
    "\n",
    "$$\n",
    "p(\\lambda|D) \\propto p(D|\\lambda)p(\\lambda) \\propto e^{-\\lambda(b+n)}\\lambda^{(a+\\sum_ix_i)-1} \\propto \\mathrm{Ga}(\\lambda|a + \\sum_i x_i, b+n)\n",
    "$$\n",
    "\n",
    "Therefore, $p(\\lambda| D) = \\mathrm{Ga}(\\lambda|a + \\sum_ix_i, b+n)$.\n",
    "\n",
    "Let's think about how the parameters of the Gamma function are updated. Remember the Gamma distribution has two parameters, the 'shape' $a$ and 'rate' $b$. Then the shape parameter is a function of the **values** of the dataset. The rate (second parameter) is a function of only the **size** of the dataset. So we can think of the hyperparameter $b$ as a *pseudo-count*, and $a$ as the sum of the 'content' of the pseudo count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Let's first calculate the posterior mean: (mean of the Gamma distribution)\n",
    "\n",
    "$$\n",
    "E[\\lambda|D] = \\frac{\\sum_1^N x_i + a}{N + b}\n",
    "$$\n",
    "\n",
    "The mean is a well behaved function of $a$ and $b$, so we can take the limit:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\lim_{a\\rightarrow 0, b\\rightarrow 0} E[\\lambda|D] & = \\lim_{a\\rightarrow 0, b\\rightarrow 0}\\frac{\\sum_1^Nx_i + a}{N+b} \\\\\n",
    "& = \\frac{\\sum_1^N x_i}{N} = \\lambda_{MLE}\n",
    "\\end{aligned}\n",
    "\n",
    "This tells in the limit the mean of the posterior becomes the maximum likelihood estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this exercise, by performing Bayesian analysis of the Poisson distribution, we discovered two things:\n",
    "1. Assuming a Gamma prior, the posterior also takes the form of a Gamma distribution\n",
    "2. In the extreme case where the parameters go to zero, the expected value goes to the MLE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
