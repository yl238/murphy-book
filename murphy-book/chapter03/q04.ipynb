{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4 Beta updating from censored likelihood\n",
    " (Source: Gelman.) Suppose we toss a coin $n = 5$ times. Let $X$ be the number of heads. We observe that there are fewer than 3 heads, but we donâ€™t know exactly how many. Let the prior probability of heads be $p(\\theta) = Beta(\\theta|1,1)$. Compute the posterior $p(\\theta|X < 3)$ up to normalization constants, i.e., derive an expression proportional to $p(\\theta, X < 3)$. Hint: the answer is a mixture distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "In this case, we have to infer a posterior for the parameter $\\theta$ based on limited information. We can't multiply the prior and the likelihood as in the notes to get a beta distribution. The only information we have is that the number of heads is less than three $(X < 3)$. So we have an event which have more than one possible outcome. \n",
    "\n",
    "However, it is simple to decompose this particular event into individual results in the sample space:\n",
    "\n",
    "$$\n",
    "p(X < 3|\\theta) = p(X = 0 |\\theta) + p(X=1|\\theta) + p(X=2|\\theta)\n",
    "$$\n",
    "\n",
    "Therefore, our problem is nothing more than a combination of the simpler case mentioned above. As such, we should expect a similar combination to appear in the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Random variables:\n",
    "- X: number of heads\n",
    "\n",
    "The posterior is given by Bayes' rule:\n",
    "\n",
    "$$\n",
    "p(\\theta|X < 3) = \\frac{p(X < 3|\\theta)p(\\theta)}{p(X < 3)}\n",
    "$$\n",
    "\n",
    "Since we want to derive an expression proportional to the posterior, we can ignore the $p(X < 3)$ in the calculation. So what is left is to calculate the likelihood, calculate the prior and combine both of them.\n",
    "\n",
    "Likelihood:\n",
    "\n",
    "\\begin{aligned}\n",
    "p(X < 3|\\theta) & = p(X = 0|\\theta) + p(X=1|\\theta) + p(X=2 |\\theta) \\\\\n",
    "& = \\binom{5}{0}\\theta^0(1-\\theta)^5 + \\binom{5}{1}\\theta^1(1-\\theta)^4 + \\binom{5}{2}\\theta^2(1-\\theta)^3 \\\\\n",
    "& = \\mathrm{Bin}(0|\\theta,5) + \\mathrm{Bin}(1|\\theta,5) + \\mathrm{Bin}(2|\\theta, 5)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the likelihood is a mixture distribution composed by 3 Binomial distributions. Let's concentrate on the prior $p(\\theta)$. As the question informs us, the prior is given by \n",
    "\n",
    "$$\n",
    "p(\\theta) = Beta(\\theta|1, 1) = \\frac{1}{B(1, 1)}\\theta^0(1-\\theta)^0 = 1 = U(0, 1)\n",
    "$$\n",
    "\n",
    "Thus the prior is a uniform distribution over the interval [0, 1]. Therefore, it becomes easy to calculate the posterior (up to a normalization constant):\n",
    "\n",
    "\\begin{aligned}\n",
    "p(\\theta|X < 3) & \\propto p(X < 3 | \\theta)p(\\theta) \\\\\n",
    "& = \\mathrm{Bin}(0|\\theta,5) + \\mathrm{Bin}(1|\\theta,5) + \\mathrm{Bin}(2|\\theta, 5)\n",
    "\\end{aligned}.\n",
    "\n",
    "Therefore, $p(\\theta |X < 3) \\propto\\mathrm{Bin}(0|\\theta,5) + \\mathrm{Bin}(1|\\theta,5) + \\mathrm{Bin}(2|\\theta, 5)$. We get the desired solution if we calculate \n",
    "\n",
    "$$\n",
    "p(X < 3) = \\int_\\theta p(X < 3 |\\theta)p(\\theta)d\\theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we showed how to infer the posterior of the parameter $\\theta$ from a censored likelihood. The final result was a mixture model formed by three binomial distributions with the same weight. A mixture model was expected because our censored likelihood could be decomposed into a sum of non-censored likelihoods.\n",
    "\n",
    "Question: the posterior of the non-censored case gives us a posterior with a Beta distribution. So why don't we arrive at a mixture model involving Beta distributions in this exercise? To answer this, we should note that the binomial and the beta distribution have the same general form $\\theta^{\\gamma_1}(1-\\theta). To be precise, we have the following relationship between the models:\n",
    "\n",
    "$$\n",
    "Bin(k|\\theta,n)\\propto Beta(\\theta|k+1, n-k+1)\n",
    "$$\n",
    "\n",
    "Unfortunately, the equality does not hold because the Beta function is not equal to the binomial coefficient, but we can express this as \n",
    "\n",
    "$$\n",
    "p(\\theta|X < 3) \\propto Beta(\\theta|1, 6) + Beta(\\theta|2, 5) + Beta(\\theta|3, 4)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
