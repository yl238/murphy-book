{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.8 MLE for the uniform distribution\n",
    "(Source: Kaelbling.) Consider a uniform distribution centered on 0 with width $2a$. The density function is given by\n",
    "\n",
    "$$\n",
    "p(x)= \\frac{1}{2a}I(x\\in[-a, a])\n",
    "$$\n",
    "\n",
    "- a. Given a data set $x_1,\\ldots,x_n$, what is the maximum likelihood estimate of $a$ (call it $\\hat{a}$)?\n",
    "- b. What probability would the model assign to a new data point $x_{n+1}$ using $\\hat{a}$?\n",
    "- c. Do you see any problem with the above approach? Briefly suggest (in words) a better approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "#### (a)\n",
    "Let's calculate the maximum likelihood estimator of the uniform distribution on the dataset $D=\\{x_1, x_2, \\ldots, x_n\\}$\n",
    "\n",
    "\\begin{aligned}\n",
    "p(D|a)  & = \\prod_{i=1}^N p(x_i|a) = \\prod_{i=1}^N\\frac{1}{2a}I(x_i\\in [-a, a])\\\\\n",
    "& = \\frac{1}{(2a)^N}\\prod_{i=1}^N I(x_i \\in [-a, a])\n",
    "\\end{aligned}\n",
    "\n",
    "From this we see that the likelihood is a combination of two terms. The first term $\\frac{1}{(2a)^N}$ is a monotonic decreasing function in $a$. Thus, as we decrease $a$ we get larger likelihoods. The second term is $\\prod_{i=1}^N I(x_i\\in[-a, a])$, which is equal to 0 if any of the points of the dataset are outside the interval $[-a, ]$, and equal to 1 otherwise. So in order to have the maximum likelihood, we have to take the minimum value $\\hat{a}$ such that $D\\subset[-\\hat{a}, \\hat{a}]$. Let's define $D_{\\mathrm{abs}} = \\{|x_1|, |x_2|, \\ldots, |x_n|\\}$. Thus the maximum likelihood estimator is given by\n",
    "\n",
    "$$\n",
    "\\hat{a} = \\mathrm{sup}(D_{\\mathrm{abs}}) = \\max(|x_i|).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Given a new datapoint $x_{n+1}$, the model would assign it the following probability:\n",
    "\n",
    "$$\n",
    "p(x_{n+1}) = \\frac{1}{2\\hat{a}}I(x_{n+1}\\in[-\\hat{a}, \\hat{a}]) = \\left\\{\\begin{array}{ll}\\frac{1}{2\\hat{a}} & if \\hat{a}\\ge|x_n+1| \\\\\n",
    "0 & \\mathrm{otherwise}\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "The problem exposed in $(b)$ is the zero count problem, where we have an unreliable MLE, given the nature of our dataset. The MLE is unreliable because it gives 0 probability for every data point greater than $\\mathrm{sup}(D_{\\mathrm{abs}})$. This becomes even more unreliable when we have small datasets.\n",
    "\n",
    "The MLE is given by $\\mathrm{sup}(D_{\\mathrm{abs}})$, which makes sense, after all, the MLE is all about maximizing the chance of our dataset to occur. \n",
    "\n",
    "Let's carry out a deeper analysis of our result. Since all datapoints were sampled from the uniform distribution that we are trying to infer, it is reasonable to assume that $a\\ge \\mathrm{sup}(D_{\\mathrm{abs}})$. In order words, if $x_i$ was sampled from a uniform distribution, then $p(x_i)\\ne 0$ and $x_i\\in[-a, a]$. This result has nothing to do with MLE yet.\n",
    "\n",
    "Now if we want to maximize the chance of our data to occurr, we already saw in (a) that we need to minimize the parameter $a$ given the restrictions above. The problem with this assumption as we saw in (b) and (c) is that it cannot explain the appearance of any new sample greater than $\\mathrm{sup}(D_{\\mathrm{abs}})$, which consist of the zero count problem.\n",
    "\n",
    "The Bayesian analysis of the uniform distribution infers a distribution for the parameter $a$ that gives zero probability to values $a < \\mathrm{sup}(D_{\\mathrm{abs}})$ and gives decreasing probabilities for values $a \\ge \\mathrm{sup}(D_{\\mathrm{abs}})$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
