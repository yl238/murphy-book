{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8e0b655384b0>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def plot_multiple_images(images, n_rows, n_cols, pad=2):\n",
    "    images = images - images.min()  # make the minimum == 0, so the padding looks white\n",
    "    w,h = images.shape[1:]\n",
    "    image = np.zeros(((w+pad)*n_rows+pad, (h+pad)*n_cols+pad))\n",
    "    for y in range(n_rows):\n",
    "        for x in range(n_cols):\n",
    "            image[(y*(h+pad)+pad):(y*(h+pad)+pad+h),(x*(w+pad)+pad):(x*(w+pad)+pad+w)] = images[y*n_cols+x]\n",
    "    plt.imshow(image, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA with an Undercomplete Linear Autoencoder\n",
    "If the autoencoder uses only linear activations and the cost function is the Mean Squared Error (MSE), then it can be shown that it ends up performing Principle Component Analysis.\n",
    "\n",
    "To perform simple PCA, we set `activation=None` and the cost function is the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer() # He initialization\n",
    "l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "my_dense_layer = partial(tf.layers.dense,\n",
    "                        activation=tf.nn.elu,\n",
    "                        kernel_initializer = he_init,\n",
    "                        kernel_regularizer = l2_regularizer)\n",
    "\n",
    "hidden1 = my_dense_layer(X, n_hidden1)\n",
    "hidden2 = my_dense_layer(hidden1, n_hidden2)\n",
    "hidden3 = my_dense_layer(hidden2, n_hidden3)\n",
    "outputs = my_dense_layer(hidden3, n_outputs, activation=None)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %Train MSE: 0.021055132\n",
      "1 Train MSE: 0.01139003\n",
      "2 Train MSE: 0.010218927\n",
      "3 Train MSE: 0.009899378\n",
      "4 Train MSE: 0.010372169\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print('\\r{}%'.format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
    "        saver.save(sess, '/tmp/my_model_all_layers.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reconstructed_digits(X, outputs, model_path = None, n_test_digits = 2):\n",
    "    with tf.Session() as sess:\n",
    "        if model_path:\n",
    "            saver.restore(sess, model_path)\n",
    "        X_test = mnist.test.images[:n_test_digits]\n",
    "        outputs_val = outputs.eval(feed_dict={X: X_test})\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n",
    "    for digit_index in range(n_test_digits):\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "        print(X_test[digit_index].shape)\n",
    "        plot_image(X_test[digit_index].flatten())\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "        plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_all_layers.ckpt\n",
      "(784,)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs, '/tmp/my_model_all_layers.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying weights\n",
    "It is common to tie the weights of the encoder and decoder (`weights_decoder = tf.transpose(weights_encoder)`). This halves the number of weights in the model, speeding up training and limiting the risk of overfitting. Specifically, if the autoencoder has a total of $N$ layers, (not counting the input layer) and $\\mathbf{W}_L$ represents the connection weights of the $L^{\\mathrm{th}}$ layer, then the decoder layer weights can be defined simply as \n",
    "$\\mathbf{W}_{N-L+1} = \\mathbf{W}_L^T$, with $L=1,2,\\cdot,\\frac{N}{2}$.\n",
    "\n",
    "\n",
    "Unfortunately this makes it impossible to use the `tf.layers.dense()` function, so we need to build the Autoencoder manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name='weights1')\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name='weights2')\n",
    "weights3 = tf.transpose(weights2, name='weights3') # tied weights\n",
    "weights4 = tf.transpose(weights1, name='weights4') # tied weights\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name='biases1')\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name='biases2')\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name='biases3')\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name='biases4')\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss = reconstruction_loss + reg_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09% Train MSE: 0.015066946\n",
      "1 Train MSE: 0.016488746\n",
      "2 Train MSE: 0.017375937\n",
      "3 Train MSE: 0.016878333\n",
      "4 Train MSE: 0.015587721\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print('\\r{}%'.format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print('\\r{}'.format(epoch), 'Train MSE:', loss_train)\n",
    "        saver.save(sess, '/tmp/my_model_tying_weights.ckpt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_tying_weights.ckpt\n",
      "(784,)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAFqCAYAAABGeW4FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAG2dJREFUeJzt3VtslXXWx/E/CD0XaCnSIpZiUQEP4aABD8SJmXAzyRg1XjhejFETjYkmmqjRxETnRu+UG6NGg8eLSSbxPDPqmJgoATUi6MhAOAhVbBEEeqAtgvreOHnfuH7r5f+49+7uar+fy5Xn/+xn77L38snzc/2n/PzzzwkAgPFuarUvAACAHDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAI06r0uvzfyii3KdW+gMmqt7eX7zPKqqOjQ36fucMCAIRAwwIAhEDDAgCEUK1nWABQFmqA95QpY/dIc6wGiHvv6aeffso+tsh5xyPusAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhkBIEEJpKuXnJvalT7X+jF1mvEnnqnOo4T01NTdY1nThxQq4/7bTTsl5fXaen1ORhpXCHBQAIgYYFAAiBhgUACIGGBQAIgdAFgNBUGMALGJw8edLUVMBg+vTpcr0KY6hzqtf3rmnaNPszPDo6mnWdKaX0448/mtoPP/xgat57UqENda1eEEV9/kWCLEVwhwUACIGGBQAIgYYFAAiBhgUACIHQBYBxp8hUBRV68NarMIEKLRShQgtFgiAqTFFfX29q3qSLY8eOmZp6T+qcKaXU0NCQtd57/bGcisEdFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEUoIAxh1vDJEa76NGDnmJPDWySL3W4OCgXH/8+HFTa2xsNLWmpiZT81J6ikoeqlpK+v2PjIyYmkpTpqTTf+qc3mgl9ZkqRUY7ebjDAgCEQMMCAIRAwwIAhEDDAgCEQOgCQFXl7jHlUQEDL3QxMDBgaip0oM6ZUkp1dXWmVlNTY2pqtJEXJFGhA3WsF1pQ16/OWVtbK9fn7oel3rt3bG4QoyjusAAAIdCwAAAh0LAAACHQsAAAIUzK0MWmTZtMbd26dfLYM844w9TU/7H+5z//Wa5vbW3NqgGTgQoOqIDB6OioXK/CBP39/ab2zTffyPVePZe6/pkzZ5paqftZqSCHmj6Rkv5M1Gt1dXXJ9e3t7aY2Y8YMU2tubpbrc6dyeKGTIrjDAgCEQMMCAIRAwwIAhEDDAgCEQMMCAIQwxRv3UWFVedH/Ovfcc01t586dFXktlSBavXp1RV6r3LxU0f33329qnZ2dFb6aU8rfVAdl1dvbm/19zk0JeqORvv/+e1PbvXu3qW3fvl2u37dvn6mpkUPeaCG1T5ZK6Q0PD5ual1AcGhoytfnz55va3Llz5frc0UyLFy+W6y+55BJTu+CCC0ytpaVFrldjqNQ1FRlN1dHRIb/P3GEBAEKgYQEAQqBhAQBCoGEBAEKYlKOZXn31VVPbsmWLPPa8884ztS+//NLUPvroI7n+tddeM7W3337b1BYuXGhqX331lTxnrmnT9J+3o6PD1L7++uvs86owxn333Ze9HpNX7j5P3n5YBw8eNDU1mkmFHlLS441UzQtdHD16VNZ/TY2WUiOYUtLf09mzZ2e9Tkop7d+/39T27Nljat5nqkJo6lrVuKmU9H5YKoihwhUp+ft8ydfKPhIAgCqiYQEAQqBhAQBCoGEBAEKYlKGLJUuWZNU8F154oaldf/318thHH33U1Pbu3WtqKnShHpwWofbUSUmHLtTrqwfcKfn/xzzwX96DdPWAXu2d5D2gb2hoMLXGxkZTmzdvnly/aNEiU1MBAS90oX4n1LWq0MLx48flOVXAQtVUuCKllA4cOGBqAwMDpuYFq9S1FglCqGO9v59S5FjusAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhTMqU4FhSe+3kpuyKJBeLUGOkDh06ZGqrVq2S69euXVv2a8LkoEYzqZSY+t6klNKcOXNMTY1W8lKCbW1tpqYSgc3NzXK9GqOkUnLqnOo6U9IpRzVGafPmzXK9GvWmqL35UkqpqanJ1NQYJpXmTEmnLNVnohKiRXGHBQAIgYYFAAiBhgUACIGGBQAIgdDFBObtv3P11VebmnoY/vjjj8v13r44wH+V+oDdW69CD2rUmDfuRwUMFC/0kfu+1H5YtbW18lhVV2Ocjhw5IterEWpz5841NTVSLiU9lk29T++9q7r6PSkH7rAAACHQsAAAIdCwAAAh0LAAACEQupjAnnvuOVnv6+szNbX/zoIFC8p9SZgkvP2Ucvc+UtMTUtIP+HP3yEpJhwHUVAkvNJC7d1aR0MmJEydM7dtvvzW1rVu3yvXq+s8//3xTu+KKK+T6rq4uU5sxY4apee9JBUTUVIxyBDG4wwIAhEDDAgCEQMMCAIRAwwIAhEDoYoLYvXu3qd19993Z6zdu3Ghq7e3tJV0TkEMFMbytOFTooaamxtS8B/wqOKBCC4ODg3K9CliogEeR6Q8qtPD3v//d1N577z25Xk3/WLZsmamdd955cv2sWbNMTX3+XhBG1VXowlufG8RJiTssAEAQNCwAQAg0LABACDQsAEAINCwAQAikBCeIN954w9TUyJeUUrruuutM7ayzzir7NQE5VErM23NN7R2lEmkqzedR35OhoSF5rBo5pVKCaj8tdZ0p6YTvpk2bTG3nzp1y/apVq0ztsssuM7XW1la5XqUX1efnpRxVSlMlAr00oDfGS+EOCwAQAg0LABACDQsAEAINCwAQAqGLgNRD4ldeecXU1APqlFJ65JFHTM17IAyUk3rArmpeaEL9m849Z5Fjm5qa5HoVMGhpaTE1NdpoeHhYnnPbtm1ZNe+aLrzwQlPr7Ow0NbXHVUo6IOGFThT1e1Tk94TRTACACYeGBQAIgYYFAAiBhgUACIHQRUDPPvusqX3wwQem9qc//UmuZ6oFKs0LPagH7EWmIqi9q9QEhtHRUbleHateywssqeCCmnShQiPbt2+X5/zwww9NTX1+v//97+X6NWvWmNrpp59uamqPrpR0aEL9TYr8TdWxRcIVHu6wAAAh0LAAACHQsAAAIdCwAAAh0LAAACGQEhzHtmzZIut33HGHqc2aNcvU/vKXv5T9moAcRfY+UsceP35crp82zf5kqXN6e8GppJx6ffU6KemRQ8eOHTM1lQhcv369POdnn31makuXLjW1q6++Wq5fsWKFqamUo7eflUo0qpr3majzeseWijssAEAINCwAQAg0LABACDQsAEAIhC7GiZGREVO7/vrr5bFqbMoNN9xgaoxgwnijAg7q374X2lAP+Ovq6kzNG0OUO9rJCw2oMEJfX5+pvfHGG6b2+uuvy3OqcU8rV640NRWuSCml9vZ2U1OfqWdwcNDUVJDF+0yVcoxhUrjDAgCEQMMCAIRAwwIAhEDDAgCEQOiiCtRD3j/84Q+mtmPHDrl+yZIlpvbwww+XfmFAmXh7J6m6ChHV1NTI9WqCRX19val5oQnvvL+mJlqkpCdw7Nq1y9Tef/99Uztw4IA8p5pqsXz5clNrbW2V6xX1mX733XfZ69Xn5AUp1KSPhoYGUyvH9AvusAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhkBKsgsOHD5uaShV5XnzxRVMrkiACKs1LlOWO9ymyd5NK9Hmvo8Y4qUScl3JU3121n9W2bdtMbebMmfKcy5YtM7Wuri5Ta2pqkuvVuCl1/V7ysbm5WdZzqb34vL9fqbjDAgCEQMMCAIRAwwIAhEDDAgCEQOiiwvr7+01t9erVWWtfeuklWVdjW4AIVBhAPfRXI5hS0mEKNS5JhStS0vtEqddS44ZSSmnLli2mtnnzZlMbHR01tYsvvlie89JLLzU1tceVGneUkt7Pyjs2lwpNeEEU9TdRNW99EdxhAQBCoGEBAEKgYQEAQqBhAQBCIHRRYevXrze1PXv2ZK29/PLLZd2bIgBEpB7we1MdhoaGTG369OmmpvaDSkkHNI4ePZpVSymljRs3mpoKXajQw+LFi+U5zzrrrKz13ntS1G+EN/0jdyqFt15N0GDSBQBgUqNhAQBCoGEBAEKgYQEAQqBhAQBCICVYJjt37pT1hx56aGwvBAhGJdrUCKWU8kf+eElalbRTo40++eQTuf6bb74xNbUflBqt1N3dLc+pEnXq/Xv7Wan9sFStCHVNXkqwSHqxVNxhAQBCoGEBAEKgYQEAQqBhAQBCIHRRJh988IGsDwwMZK1fsmSJqdXX15d0TcBkUCRgoMIEaj8sL7ShAhYrV640ta6uLlNraWmR51Tjog4dOmRq3h5X6v17AQ1Fvddy7F1VCdxhAQBCoGEBAEKgYQEAQqBhAQBCIHRRBZdeeqmpvfvuu6ZG6AKTlRd6KDKBQVHHqiDFRRddJNcvWrTI1BobG01N7dHlhS7U91ytV+GQlPRnpT6nIkEMdex42IePOywAQAg0LABACDQsAEAINCwAQAg0LABACFOqNIJjfM79QGTVjzBNUr29vePu+1zkd02NNvIScSplqI5Ve0R5KT81ckml/Eo1HlJ+uTo6OuTFcocFAAiBhgUACIGGBQAIgYYFAAihWqELAAAK4Q4LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEMK0Kr3uz1V6XUxcU6p9AZNVT09P9vf555/toVOmTLw/nXqfntz3750zyudX5Po7Ozvlm+IOCwAQAg0LABACDQsAEEK1nmEBQGG5z4a85zq5z9BKfV5U5Jy5ijyrKnKsuq5KPGssx7M27rAAACHQsAAAIdCwAAAh0LAAACHQsAAAIZASBFBVlUikFUnk/fTTT9nrf/zxR1ObOjXvv/uPHz8u6w0NDaam3r/3mdTW1ma9lnqfKenrz00Oeio1fYM7LABACDQsAEAINCwAQAg0LABACIQuyuTll1+W9WPHjpnap59+ampPP/109ms9+OCDpnbllVea2u9+97vscwJjIXdkUZHRSCpM4D30V8eOjo5mHZdSSocPH5b1X1PhjPr6ennswMCAqZ08edLUvPekQhuqNm2a/rlXr1VTU2Nq3mcyltujcIcFAAiBhgUACIGGBQAIgYYFAAhhSql7tPxGVXnRcrn99ttN7amnnqrClfyvpUuXmtqHH34oj505c2alL6caKvO/1uOUenp6sr/PldjPSgUchoeH5fqRkRFTU6GHb7/9Vq7/8ssvTe3IkSNZ1+m9dzWpYv78+abW2dkp16tjVejC+96rMIa61iKTMryAh6Jea8GCBfIfAHdYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBAYzXQKlUgELl++3NSuvfZaU9u5c6dc//zzz5vatm3bTO1vf/ubXH/zzTef6hKBqvISdWqMkKodPXpUrt+3b5+p7dq1y9T+/e9/y/V79+41NZXyU7XTTjtNnlOlHFXNS/l1d3dnHeu9vvqsVfLP289LpQcbGxvlsQqjmQAAEw4NCwAQAg0LABACDQsAEAKhi1/09PTI+jPPPJO1/uKLL5b1f/7zn6amxqao/WfUg9eU9EPiDRs2mNqhQ4fkeqDSSh355v3bP3HihKmp0Uh9fX1yvQpNqIDGjBkz5Pq1a9eaWldXl6mpIMH+/fvlOb36r3mfqfrtmDVrlqmpIEVKeo8v9Tl763PHUHnri+AOCwAQAg0LABACDQsAEAINCwAQAqGLX3gBBfXwUAUs/vWvf8n1TU1Nv/mannvuOVn/5JNPstZfddVVv/m1gbGiJiV4UxlUvchUho6ODlNToQlv76l58+aZ2uzZs03t4MGDpvbOO+/Ic6qpGv39/abm/ZYsXrzY1Nra2kxt+vTpcr36/FTowluvfiPV9BFvj6wiYQzusAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhkBL8xYoVK2RdpQfVKJT6+vqyX5M3FuqHH34o+2sB5VRkjyOVPvOSY2pkk0qfnXnmmXK9SrSplN+CBQvk+ubmZlMbGRkxtd7eXlPz9tjasWOHqbW0tJiaSlN6VMrPoxJ9Ko3ppQTV31r9nby/KfthAQAmHBoWACAEGhYAIAQaFgAgBEIXpzBz5swxeZ0XX3zR1LZu3Zq9Xu3T093dXdI1AWOh1Af0KgSl9pzztLa2mpoXohodHTW17du3m9qbb75pap9//rk8p7rW5cuXm5q3554KmKjPT127d6wKXXjhCBXGKBKkKLJ3GndYAIAQaFgAgBBoWACAEGhYAIAQCF1UwWeffWZqt956q6kV2dNn3bp1pub9n+lAORV5aK6of6dFzqnWq+kNKaVUV1eXtV4FQVJK6cCBA6b21ltvmZras84759KlS01t9erVprZq1Sq5XoVGjh49amrehBwVWlFBjELhiAJ7XBXBHRYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBFKCVbBx40ZT8xKBym233WZq55xzTknXBIyF3L2TvP2c1Mggtd77Pqn9rFT67ciRI3K9Gq/0n//8x9SGhoZMzdtja/HixaZ29tlnm1pbW5tcr65fJQK91LBK9Km/U5H9uIqkBNkPCwAw4dCwAAAh0LAAACHQsAAAIRC6qLCbbrrJ1P76179mrb3rrrtk/d577y3pmoByKnXvI/WA3gsIqDCG2rvKW6/qap+o/fv3y/Uff/yxqR0+fNjUmpqaTG3evHnynLNnzzY1FQ7x9rMaHh42NRX68Pb2yw2yeHL3zvJGO7EfFgBgwqFhAQBCoGEBAEKgYQEAQiB0USbqIWdKKf3jH/8wNfXwdO7cuab2wAMPyHOq/WuAalEPzb0gRu7DeO+hv5rgoMIEKgjgvX5vb6+pffHFF3L93r17TS33+6zCISml1NDQYGrqOtUeVyml1N/fb2rTptmfdi/coD4rdU3e6yvqN8qblEHoAgAw4dCwAAAh0LAAACHQsAAAIRC6KJPrrrtO1r/77rus9Xfeeaeptba2lnRNwFgoMtWgVHV1dVm12tpauV4FJL7//ntT27Fjh1zf19dnamqCRXt7u6ktXLhQnvPcc881NRVaUK+dkt5KZc6cOaamPqeUUjp58qSs51JBGC/0UirusAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhkBL8DT799FNTe//997PXX3PNNaZ29913l3JJwLhSZI8sdaw3fkyl/7z0m3LkyBFT27Nnj6l99dVXcr1K1M2YMcPUuru7TW3FihXynPPnzze1IilL9Zmo0UreZ6qSk2qPLW9cljpvkXFdRXCHBQAIgYYFAAiBhgUACIGGBQAIgdDFKYyMjJja/fffb2pqPIln5cqVpsYeV5gM1MN4VVP7OaWkAxZTp9r/7vb2blIjlzZu3GhqPT09cv2ZZ55pasuXLze1ZcuWmZoa15SS3idKBSHUvl/e+twgREopDQwMZJ3TC12o0Il6/XKMa+IOCwAQAg0LABACDQsAEAINCwAQAqGLU3jyySdN7b333stef9NNN5kaUy0w0XkP+HP3zvJCF+pYtR+Uml6RUkobNmwwtc2bN5vasWPH5Po1a9aYmppgocIZXjCrv7/f1NT7nD59ulyvwgwqNDE4OCjXHzp0yNROnDhhal7oI3eChRfaKBLG4A4LABACDQsAEAINCwAQAg0LABACDQsAEAIpwVN44IEHSlr/2GOPmRpjmDCRFNm7SVF7N6mUWkp6NJMaY9Tb2yvX792719RUSq+trU2uX7hwoamp77O6Jm9c1NDQkKnV19ebWnNzs1yvPn/1/r1xU+ozUa+/ZMkSuV6Nr1PjsryUYxHcYQEAQqBhAQBCoGEBAEKgYQEAQiB0UWHqgap6IFmq2tpaU/NGnqgRKWq8jUc9ZF23bl32ekVdqxd4KcfDW5RP7rgl71g1BskbA6TOq0YeqdFEXv3kyZPZ6w8ePGhq+/fvN7UioQf13W1sbDQ1b1yVCo2o0VQHDhyQ69V3r7u729S8EUzqWnPHRaXkvy+FOywAQAg0LABACDQsAEAINCwAQAiELirsjDPOGJPXue2220xt3rx58ti+vj5Te+KJJ8p+TaXyPrtbbrlljK8E5eJNsPg1L7Sh1qvQhLf3lJpKoR76Hz58WK5X+2nt2rUr65q8YJMKmKhgkTpnSnqqhgpieKEHNcFCXVNLS4tcr0JcKlhWjrAZd1gAgBBoWACAEGhYAIAQaFgAgBBoWACAEEgJnsINN9xgauvXr6/Clfz/nnzyybKf0xuZ4o18+rUbb7xR1i+55JKs9ZdddlnWcaiuUvfDUryUn0qkqX+PHR0dcr3az0qNT9u2bZtc//nnn5va4OCgqanxZd5+Vupa586da2peylAlCmfNmmVqXV1dcv2aNWtMTSV01QimlPTvRJGUYJF/P9xhAQBCoGEBAEKgYQEAQqBhAQBCmFKJB6YZqvKi5fLCCy+YmveQONfWrVtNrdRxSffcc4+sL1q0KGv9H//4R1k//fTTf/M1VZDerAcV19PTk/19Vr83auSQGqGUUn7gxxtj9PXXX5uaCljs27dPrt+9e7epqdFMw8PDptbe3i7P2dbWZmp1dXVZtZR06EIFLLzQxYIFC0xNjWby9sNSfxMVsPD+durfRGdnp3wx7rAAACHQsAAAIdCwAAAh0LAAACEQusBEQeiiSkoNXah9mrzfJRUwUAENdVxKej8tNT1D1VLS+2T19PSYmpqe4U2KUGGGIr/LaqqFmqrhTa5paGgwNfX5edeUe/1eaEMhdAEACI2GBQAIgYYFAAiBhgUACIGGBQAIgf2wAFRV7miflHTSTCX6amtr5XqV1FPn9BJtc+bMMbVzzjkn65q8lJ0aIzU6OmpqRfYI8z4/RaUs1d5bRc5ZJBHIflgAgAmHhgUACIGGBQAIgYYFAAiB0AWAMZM7xsd7EK/qauSQGsFUhAo9pKQDDmq0lOLtB6U+ExXE8EYrKWq0kheEUJ9VJUIT3jmLvBZ3WACAEGhYAIAQaFgAgBBoWACAEAhdAKiqIvtBqboKDXjr1bFqqkNdXZ1cr6Y9qAkUatKG2ncqJb13lgpoFAmSFNljTNWLTLXIPWc5cIcFAAiBhgUACIGGBQAIgYYFAAiBhgUACIGUIIAxo9JjRUbz5J5TjVDy5Cb/iqxXo5UGBwflepUIVKOhSt0jrIhKpfxKxR0WACAEGhYAIAQaFgAgBBoWACCEKeP14RoAAP8Xd1gAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEP4HIYt/jwf3JNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs, '/tmp/my_model_tying_weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training one Autoencoder at a time in multiple graphs\n",
    "\n",
    "There are many ways to train one autoencoder at a time. The first approach is to train each autoencoder using a different graph, then we create the stacked autoencoder by simply initializing it with the weights and biases copied from these Autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def train_autoencoder(X_train, n_neurons, n_epochs, batch_size, learning_rate=0.01, l2_reg=0.0005, seed=42,\n",
    "                     hidden_activation=tf.nn.elu, output_activation=tf.nn.elu):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        tf.set_random_seed(seed)\n",
    "        \n",
    "        n_inputs = X_train.shape[1]\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "        \n",
    "        my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_reg))\n",
    "        \n",
    "        hidden = my_dense_layer(X, n_neurons, activation=hidden_activation, name='hidden')\n",
    "        outputs = my_dense_layer(hidden, n_inputs, activation=output_activation, name='outputs')\n",
    "        \n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "        \n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            n_batches = len(X_train) // batch_size\n",
    "            for iteration in range(n_batches):\n",
    "                print('\\r{}%'.format(100 * iteration // n_batches), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                indices = rnd.permutation(len(X_train))[:batch_size]\n",
    "                X_batch = X_train[indices]\n",
    "                sess.run(training_op, feed_dict={X: X_batch})\n",
    "            loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "            print('\\r{}'.format(epoch), 'Train MSE', loss_train)\n",
    "        params = dict([(var.name, var.eval()) for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])\n",
    "        hidden_val = hidden.eval(feed_dict={X: X_train})\n",
    "        return hidden_val, params[\"hidden/kernel:0\"], params[\"hidden/bias:0\"], params[\"outputs/kernel:0\"], params[\"outputs/bias:0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train two Autoencoders. The first one is trained on the training data, and the second is trained on the previous Autoencoder's hidden layer output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE 0.01851794\n",
      "1 Train MSE 0.01868272\n",
      "2 Train MSE 0.018467719\n",
      "3 Train MSE 0.019231753\n",
      "0 %Train MSE 0.004236086\n",
      "1 Train MSE 0.004832612\n",
      "2 Train MSE 0.0046686903\n",
      "3 Train MSE 0.0044038594\n"
     ]
    }
   ],
   "source": [
    "hidden_output, W1, b1, W4, b4 = train_autoencoder(mnist.train.images, n_neurons=300, n_epochs=4, batch_size=150, output_activation=None)\n",
    "_, W2, b2, W3, b3 = train_autoencoder(hidden_output, n_neurons=150, n_epochs=4, batch_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a Stacked Autoencoder by simply reusing the weights and biases from the Autoencoder we just trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "hidden1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "hidden2 = tf.nn.elu(tf.matmul(hidden1, W2) + b2)\n",
    "hidden3 = tf.nn.elu(tf.matmul(hidden2, W3) + b3)\n",
    "outputs = tf.matmul(hidden3, W4) + b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAFqCAYAAABGeW4FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGtZJREFUeJzt3UtoXeXXx/HVa5ImTdKkSWt6Nb1ZrWIrUm8DceBE+IuKA3WgqKAICgoqCoI60Zl2IiqK94EgqDjwjvWGFq1abJSamrZqbJpYm6RNm/QS34nv+5es3/P22Z6Tnqz0+xku9rP3zokny83+dT1T/vrrLwMAYKKbWukbAAAgBw0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABDC9Apdl3+tjHKbUukbOFn19fXxfUZZtbS0yO8zT1gAgBBoWACAEGhYAIAQKvUOCwAmhdwB4lOm8Jq1VDxhAQBCoGEBAEKgYQEAQqBhAQBCoGEBAEIgJQjgpKbSe6Ojo/JYVZ861f9//8yZM7PPqdarY48dOybXp+q5x02bNi2rNhHwhAUACIGGBQAIgYYFAAiBhgUACIHQBYDQSh15VGS9CiOogIU659GjR+U51WinIqELdWxVVZWrpYIUqp57TycaT1gAgBBoWACAEGhYAIAQaFgAgBAIXQAII3cqRZEghQozjIyMyGOnT/d/MlVoIXf6hJlZdXW1qx0+fNjV1ESMIveU+kxUwEJdP7W+1M+/CJ6wAAAh0LAAACHQsAAAIdCwAAAh0LAAACGQEgQw4ajkmplO36laKlF36NAhV1OJuBSV6FPXP3LkiKvV1NTIcw4MDLhakT2qVF0l99QIKTN9r0pqNJNKBJaanEzhCQsAEAINCwAQAg0LABACDQsAEAKhCwATTip0ofaUUi/z1bgiMx0wUKGLVMBgxowZrqbCFPX19a7W398vz6nGQKmfqaGhQa5XP5MKPRQZ7aQ+5yKhC3XOIqOhUnjCAgCEQMMCAIRAwwIAhEDDAgCEcFKGLr788ktX27Bhgzx2wYIFrqZesl5//fVyfVNTU1YNwH+lXsQPDQ1l1VL7We3du9fVBgcHXS01/UKFKVQYQl1/+/bt8pz79u1ztVNOOcXVmpub5frh4WFXUxM9Vq1aJdfPnz/f1WbNmuVqqdCFCnOogEXqd5oKg8hjs48EAKCCaFgAgBBoWACAEGhYAIAQaFgAgBCmFBmLUUYVuej/UmmZzs7OcbmWShCdd95543Ktclu6dKms33fffa62ePHicb6b49JzXzDu+vr6Svo+qzFEajSQmR5vpJJ/O3bskOt37drlaipll0oZqmPVGKTe3l5X27p1qzynWn/aaae5mtqLy8ysr68v69g1a9bI9RdffLGrLV++3NXUWCqz/ERgKg2ofv6Wlhb5feYJCwAQAg0LABACDQsAEAINCwAQwkk5mumNN95wte+++04ee8YZZ7haR0eHq23atEmuf/PNN13t3XffdbVTTz3V1VIvjnOl9gRSY19+/fXX7POqMMa9996bvR6TXyrMpeqqpvZ4MtNhDDVaSQURzHRoQ31PDhw4INera6nQiAoYLFq0SJ5TBbPUGKbUfloqMKaOVeEGM7OVK1e6mvqOp9ZXVVW52niF+XjCAgCEQMMCAIRAwwIAhEDDAgCEcFKGLlavXp1VSznrrLNc7ZprrpHHPvroo662c+dOV1Ohi66urux7UmbOnCnrKnShrp96ca3+FT7wT2r6gVn+BITUehWQUAGN2bNny/VtbW2yPtbcuXNlXe0zpfaJUtdPhaDUZ6LOqfbNMtOBMTX9IxVkUddSn3+hfavEsSqckrpW8rzZRwIAUEE0LABACDQsAEAINCwAQAg0LABACCdlSvBEUvvS5KbsiiQXi1BjpP744w9XW79+vVx/6aWXlv2ecHLITY+l9sNS44HUd2zhwoVyvRojVFNT42qp0UyzZs1yNZX+U8elUnrqZ1Kf0yeffCLXq59/2bJlrrZixQq5ft68ea6WSlkqKuWnkoeplGGRMU48YQEAQqBhAQBCoGEBAEKgYQEAQiB0MYkNDQ3J+hVXXOFq6iXp448/Lterl9TAv6Ve2qf2XlKjkRobG7POaWbW0tKSdS31fTAzmzFjhqup74MKWKRGM6nr79+/39X27NmTfU9r1651tVWrVsn1au8rNdYtFYRR9SJjnBjNBACYdGhYAIAQaFgAgBBoWACAEAhdTGLPP/+8rPf09Lhac3Ozqy1ZsqTctwQ4qYCFoqYiNDQ0uFp9fb1cX1tb62qpqRa511cBBTVRo8h+WJ2dna6W2p9OhRbmzJnjaiqcYpYfREntZ6XqKnSRmmhB6AIAMOnQsAAAIdCwAAAh0LAAACEQupgkfv75Z1e76667std/8cUXrjZ//vyS7gkYS714V5MSUgEFtW1HXV2dqxWZxqLuKRXEUGGKw4cPl3T97u5uV/voo49c7YcffpDr1f2r0ElbW5tcr6Z6qCDFyMiIXJ+rSLgihScsAEAINCwAQAg0LABACDQsAEAINCwAQAikBCeJt956y9XUnjxmZldffbWrtbe3l/2egLFUUkzV1B5PZnpkUHV1taupcUlmep8p9T1JrVfpObVHl0oT9vf3y3Nu27bN1b799ltXSyUX1T5XqqZGWJnpz0/9TlLJzVLTg0XwhAUACIGGBQAIgYYFAAiBhgUACIHQRUDqJfHrr7/uaurFr5nZI4884mpF9iQCyqnIC341hkitV+OSzMwOHjzoamo0VIq6LxVaGB4edrWuri55ThWY2rRpk6upPa7MzM444wxXO//8812tqalJrs8NwqSk/s6MxX5YAICTBg0LABACDQsAEAINCwAQAqGLgJ599llX+/TTT13t2muvleuZaoGJbupU/f/SuftppaYvqLo6pwpSmOXvvdXT0+Nq6jtqpveiUwGLs88+W65fv369qzU3N7tabW2tXK9CDyrYlfqdqP20cq9TFE9YAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBICU5g3333nazffvvtrtbY2OhqDz/8cNnvCSg3tcdUai83dawal5RKrql9rlT6bfbs2XK9Gm+kxjDt3LnT1T7++GN5TrWf1rp161xtzZo1cr1K/aq/B6mUntojTFGffYr6nIusT+EJCwAQAg0LABACDQsAEAINCwAQAqGLCUK9eL3mmmvkserl5XXXXedqjGBCBEX2Y1IBiaGhIVdTL/3N9BgmNW4pNZpJfff27Nnjau+//76rdXR0yHOq/aQWLlzoahdccIFcr0ZDqSBKkdCDOjY17kp9VuUIWCg8YQEAQqBhAQBCoGEBAEKgYQEAQiB0UQHqX+FfdtllrrZt2za5fvXq1a720EMPlX5jwDgrErBQVOhCrR8cHJTr1T5RKqChQgtmeirE119/7WpbtmxxtVRoYdmyZa6mplqkQlQNDQ2upj4TNZHDTAdRVGgitR9Wqp5zHbOCv//sIwEAqCAaFgAgBBoWACAEGhYAIAQaFgAgBFKCFfDnn3+62saNG7PXv/TSS66m9ukBJhqVPiuSElNjgHJTamY6PTht2jRXO3DggFyvvrsqJdjd3e1qra2t8pwqJbh27VpXq6+vl+vV/atEYmqPMXWsSvSlxl2p86qUZZHfcwpPWACAEGhYAIAQaFgAgBBoWACAEAhdjLOBgQFXO++887LWvvzyy7KuXsgCEaiAhApizJgxI/ucKgyQesGvjt27d6+r7du3T67fvHmzq23atMnVent7XU2NhTIzW7lypavNmzfP1dRINzO9H5gKQqRGI+WGVlS4w0z/rlL3WiqesAAAIdCwAAAh0LAAACHQsAAAIRC6GGfPPfecq3V1dWWtveiii2S9HP9iHJgo1Mv81FQG9TJfhQbq6urkerUnlLqWCk2YmXV2drra4cOHXU1Nnjn33HPlOdetW+dq6mcqsp9VkePU35Mi00NKnV5SBE9YAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBICZaJSg+ZmT344IMn9kaAYHJTbmY6kaccPXpU1tXeT+qcKvlmZlZVVeVqp59+etY9qX2vzMwaGhpcTSUXU8k79fnlpinN9Gil1M+vqPMW+Z0WwRMWACAEGhYAIAQaFgAgBBoWACAEQhdl8umnn8r64OBg1vrVq1e7Wk1NTUn3BERQZIxP7gv+VDgjFcYYq7a2VtaXLFniam1tbVnnXLBgQfa1VGgiNZpJ/Z1QP2cqdKECFqm9r5TxClgoPGEBAEKgYQEAQqBhAQBCoGEBAEIgdFEBF1xwgau9//77rkboAjg+9dJ/5syZ2eurq6uzaqm6Ckio0ELq+6ymZ6hzTp+u/1yrgIW6fircEml/PZ6wAAAh0LAAACHQsAAAIdCwAAAh0LAAACFMOZFjNf6hIhfFpBYn6jTJ9PX1Tbjvs0rZpRQZTZQabzSW+rua+lub+ze4SJpPHRspDdjS0iJvlicsAEAINCwAQAg0LABACDQsAEAIlQpdAABQCE9YAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBoWACAEGhYAIAQaFgAgBCmV+i6f1Xoupi8plT6Bk5WXV1dfJ9RVu3t7fL7zBMWACAEGhYAIAQaFgAghEq9wwKACWvKFP1K9K+//Os6dezo6Gj2OUuVe0+TAU9YAIAQaFgAgBBoWACAEGhYAIAQaFgAgBBICQKYcFTyzWxipt/Uvc6cOdPVjh49mr3+2LFjWbWUqVP9s8j06frPfaSUIU9YAIAQaFgAgBBoWACAEGhYAIAQCF2UySuvvCLrQ0NDrrZ582ZXe/rpp7Ov9cADD7jaJZdc4moXX3xx9jmBiaTIS//c0ELq2JGREVdLBSQOHz7sajNmzHA1df+pc+7bt8/VVEBCXcfMrKamxtVU6EMFMVLHquungjCp844HnrAAACHQsAAAIdCwAAAh0LAAACFMSb1IG2cVuWi53Hbbba721FNPVeBO/uv00093tc8++0we29DQMN63UwkT85/mnwS6urrK/n1O/V1SdRVmGB4elutVCEqFHn755Re5/vfff3e1AwcOuNqvv/7qaqkgiQqILF++3NVaW1vl+ra2NldbtGiRq9XV1cn1KmChatOmTZPrVb3UIEZ7e7v8sHjCAgCEQMMCAIRAwwIAhEDDAgCEQMMCAITAaKbjGI9E4Nq1a13tqquucrXOzk65/oUXXnC1H374wdVee+01uf6mm2463i0CJ4xK/o2Ojspj1Wik/fv3u9off/wh1+/YscPVvvnmG1f78ccf5fq+vj5XUyk5dZ9qBJSZWX19vasdOXLE1aqrq+X6xYsXu5pKBKrrmJlVVVW5mvr8U8lLlQhUycdUcrDIGC6esAAAIdCwAAAh0LAAACHQsAAAIRC6+FtqFMszzzyTtf7cc8+V9XfeecfVZs2a5WpqT5rUnj7bt293tc8//9zVUi+egYkk9d+5osIMajTSnj175Prvv//e1Xp6elytsbFRrlcj0JqamlytubnZ1X766Sd5TlVPjVFSSg09qDFMatyVOs5MB0TU3l3lGAPIExYAIAQaFgAgBBoWACAEGhYAIARCF39LBRTUi0IVsPjggw/k+iIvT8d6/vnnZf2rr77KWn/55Zf/62sDJ4qaFKFe5JvpCQxqUkPqe7dmzRpXW7FihaupaTRmZu3t7Vn31N3d7WqDg4PynLt373Y1NVWiv79frk9NwBhLBSnMdEBDXT+1Xk2qUOcsMtEihScsAEAINCwAQAg0LABACDQsAEAINCwAQAikBP+2bt06WVfpQTVGqaampuz3lBoLpcbTABGo1G2R9JgaD6RScnPnzpXr1XgitZ/U2WefLder7776G9HR0ZF1nJlZb2+vq5111lmultrPSiX61Od86NAhuV4lMtXvJPV3R9XnzJkjj1XYDwsAMOnQsAAAIdCwAAAh0LAAACEQujiOhoaGE3Kdl156ydW2bNmSvf7SSy91tWXLlpV0T0C5qRfsKiCQGjekjlUv/WfPni3Xq73oli5d6mpq3JOZ2cGDB11t27ZtrrZx40ZX+/HHH+U51d5RtbW1rtbW1ibXq3puOCVFfc6p0UwqzKECImoEV1E8YQEAQqBhAQBCoGEBAEKgYQEAQiB0UQHffvutq91yyy2uNjIyItefcsoprrZhwwZXUy9zgRNBvbQ305Mm1N5Jqf92VRhCBTlS352WlhZXUwGNoaEhub6np8fV3n33XVfbvHmzq6X2w1JTOVQ4ZPXq1XJ9a2urq6nQRWqPMTWlRwUsDhw4INc3Nja6mgpYqN99UTxhAQBCoGEBAEKgYQEAQqBhAQBCoGEBAEIgJVgBX3zxhaulUk3Krbfe6morV64s6Z6AE2F0dNTViiTKVCJQ7VGlRhuZ6fSdSsSpNKCZ2XvvvedqauSS+pkWLlwoz9nc3OxqKrmoRkiZ6Z9p165drpYaM6c+U5UyTI2rSiVCc65TFE9YAIAQaFgAgBBoWACAEGhYAIAQCF2MsxtvvNHVXn311ay1d955p6zfc889Jd0TMN6KvGAvErrIfcGf2ntJjSdSI4e+/PJLub6jo8PVfvvtN1dT+2atWrVKnnPOnDmutn79eldL7WfV39/vamoMlNqjykwHLFQIrK6uTq5X+5GVI2Ch8IQFAAiBhgUACIGGBQAIgYYFAAiB0EWZpPaKefvtt11teHjY1ebNm+dq999/vzyn+pf9QARq0kXuHllm+Xu8qeuY6TBCZ2enq23dulWu37t3r6upSRkqSJEKLSxevNjV1KSLgYEBuX7Hjh2upj5TdZ9mOoiiQhOpIIX6rMdrLz6esAAAIdCwAAAh0LAAACHQsAAAIRC6KJOrr75a1nt7e7PW33HHHa7W1NRU0j0BE01qgsVYqRf8ar16wZ8KXaipDOo7qoJRZnorj4suusjV1PYmKkhhZrZ8+XJXa2xsdDUVGDEzO3TokKupSR9qIoaZnoChQi/qszPTvyu1PjV9pAiesAAAIdCwAAAh0LAAACHQsAAAIdCwAAAhkBL8FzZv3uxqGzduzF5/5ZVXutpdd91Vyi0Bk0pq3yuVNCuyn9b+/ftd7c8//3S11GghlahTY9Xmzp3raqmfSSUC1ai3VPJRjYFS45ZSn4na+0rt55W6vvr8q6qqso4riicsAEAINCwAQAg0LABACDQsAEAIhC6OQ409ue+++1wtNbZEOeecc1yNPa5wslIv86dP13+aVEBASX0f1d5RO3fudLVt27bJ9a2tra6mAha5a830Plnq51fhkNSx6udPhR7UZ1pdXe1qQ0NDcn2uVOgkNYZL4QkLABACDQsAEAINCwAQAg0LABACoYvjePLJJ13tww8/zF5/4403uhpTLTDZpV6wKyp0kZqqoM6rAgZ79+6V61XoYteuXa62e/duuX7ZsmWupvbImj9/vqupiRhmeqqGmlSRCieoz0oFKTo7O+V6NQGjubnZ1VQQI3Ws2g8rNT2kCJ6wAAAh0LAAACHQsAAAIdCwAAAh0LAAACGQEjyO+++/v6T1jz32mKsxhgmTXSrRlpseTKUEh4eHs2qp0Urbt293NZUIVOOSzPTeVYsWLXI1tUeVuk8zs8HBQVcrsh+WqqvkY3d3t1yvUpZLlixxtfb2drlefVYqOVkOPGEBAEKgYQEAQqBhAQBCoGEBAEIgdDHO1MtTNQqlVFVVVa6W2v9GjU3J3WfITO8RtmHDhuz1irrXVOClHCNeMHGoIEYqtKH2fhoYGHA19d+omdm+ffuyrq+CEGZm/f39rvbTTz9lXf/gwYPynOpa6vuY+j6ra/X09Lja77//Ltervx1Lly51tVSQInc/K/bDAgCcNGhYAIAQaFgAgBBoWACAEAhdjLMFCxackOvceuutrtbW1iaPVS9kn3jiibLfU6lSn93NN998gu8E5ZIbsEgFk9SLfxXESO2HpQIG6tihoSG5/uuvv3Y1Nf2iqanJ1fr6+uQ5VZiivr4+6zgzHQTZs2ePq6npG2ZmixcvdjV1/7W1tXK9ui/1+ysSrkjhCQsAEAINCwAQAg0LABACDQsAEAINCwAQAinB47juuutc7bnnnqvAnfz/nnzyybKfU6WvzNJppbFuuOEGWT///POz1l944YVZxyGOUsf4qLpK1K1YsUKuV+OJVq5c6WpfffWVXL9161ZXU/tJqe9Iaj8s9T1T95QaSabWz54929WWL18u15955pmuphK61dXVcr36nebWiuIJCwAQAg0LABACDQsAEAINCwAQwpTUy81xVpGLlsuLL77oaurFaxFbtmxxtVLHJd19992ynnr5OtZ//vMfWW9tbf3X9zSOSn+ji3+lq6sr+/ucO5op9YJehRnUOXt7e+X63bt3u1pnZ6er/fzzz3J9R0eHq3V3d7uaGn/W0NAgz6n2njrttNPksYr6TNRYtkWLFsn1S5YscbW5c+dmXcdMh0HUsblhLTOz9vZ2+R8AT1gAgBBoWACAEGhYAIAQaFgAgBAIXWCyIHRRIUVCF6VSL/jV3kupF/wjIyOudvToUVc7cuSIXD8wMOBqKnSh9qhKTY6pq6tztebmZldL7dGl1qvQitpLLFVX61OfaZEwRS5CFwCA0GhYAIAQaFgAgBBoWACAEGhYAIAQSAlisiAlWCGlpgTV36DU3yWVXlPpu1Qir6qqKquWGg2VOu9YKtGXGt+mzjk6Opp1TjN9r8eOHTveLf4f9fOr5KS6p9T1S0VKEAAQGg0LABACDQsAEAINCwAQQt4bRAAYJ0X2w8p9wa9CA2b5YYZUwKC6utrVcsdF1dTUyHOqcVHq+qnAhzq2yLgqtb5CYbzj4gkLABACDQsAEAINCwAQAg0LABACoQsAYZQaBkiFMXKvo9ar0IYKSKjAhpkOPajrpO4pN3RRZPqFOud4TLQoiicsAEAINCwAQAg0LABACDQsAEAINCwAQAikBAGEViT9VqojR464mkrkqZTdoUOH5DlzE31FEpKp0VK51D1NBBPzrgAAGIOGBQAIgYYFAAiBhgUACGHKRN33BACAf+IJCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABACDQsAEAINCwAQAg0LABDC/wBFoMxmIz9TNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3745401188473625&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul/b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 784\\n          }\\n          dim {\\n            size: 300\\n          }\\n        }\\n        tensor_content: &quot;<stripped 940800 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;MatMul/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        tensor_content: &quot;<stripped 1200 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Elu&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_1/b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n          dim {\\n            size: 150\\n          }\\n        }\\n        tensor_content: &quot;<stripped 180000 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Elu&quot;\\n  input: &quot;MatMul_1/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 150\\n          }\\n        }\\n        tensor_content: &quot;<stripped 600 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul_1&quot;\\n  input: &quot;add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Elu_1&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_2/b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 150\\n          }\\n          dim {\\n            size: 300\\n          }\\n        }\\n        tensor_content: &quot;<stripped 180000 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_2&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Elu_1&quot;\\n  input: &quot;MatMul_2/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        tensor_content: &quot;<stripped 1200 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul_2&quot;\\n  input: &quot;add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Elu_2&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_3/b&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n          dim {\\n            size: 784\\n          }\\n        }\\n        tensor_content: &quot;<stripped 940800 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_3&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Elu_2&quot;\\n  input: &quot;MatMul_3/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 784\\n          }\\n        }\\n        tensor_content: &quot;<stripped 3136 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul_3&quot;\\n  input: &quot;add_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3745401188473625&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
