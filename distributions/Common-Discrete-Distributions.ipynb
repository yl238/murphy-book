{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common discrete distributions\n",
    "\n",
    "### The binomial and Bernoulli distribution\n",
    "\n",
    "Suppose we toss a coin $n$ times. Let $X \\in \\{0, \\ldots, n\\}$ be the number of heads. If the probability of heads is $\\theta$, then we say $X$ has a **binomial** distribution. The probability mass function is given by \n",
    "\n",
    "$$\n",
    "\\mathrm{Bin}(k|n, \\theta) \\triangleq \\binom{n}{k}\\theta^k(1-\\theta)^{n-k}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\binom{n}{k}\\triangleq \\frac{n!}{(n-k)! k!}\n",
    "$$\n",
    "is the number of ways to choose $k$ items from $n$ (n choose k). The distribution has the following mean and variance:\n",
    "\n",
    "mean = $ n\\theta$, var = $n\\theta(1-\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we toss a coin only once. Let $X\\in\\{0, 1\\}$ be a binomial random variable, with probability of heads of $\\theta$. We say $X$ has a **Bernoulli** distribution. This is written as $X\\sim\\mathrm{Ber}(\\theta)$, where the pmf is defined as \n",
    "$$\n",
    "\\mathrm{Ber}(x|\\theta) = \\theta^{\\mathbb{I}(x=1)}(1-\\theta)^{\\mathbb{I}(x=0)}\n",
    "$$\n",
    "In other words,\n",
    "\n",
    "$$\n",
    "\\mathrm{Ber}(x|\\theta) = \\left\\{\\begin{array}{lr}\\theta & \\mathrm{if}\\,x=1\\\\ 1-\\theta & \\mathrm{if}\\,x=0\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The multinomial and multinoulli distributions\n",
    "\n",
    "The binomial distribution can be used to model the outcomes of coin tosses. To model the outcomes of tossing a $K$-sided die, we can use the **multinomial** distribution. This is defined as follows: let $\\mathbf{x} = (x_1, \\ldots, x_K)$ be a random vector, where $x_j$ is the number of times side $j$ of the die occurs. Then $\\mathbf{x}$ has the following pmf:\n",
    "\n",
    "$$\n",
    "\\mathrm{Mu}(\\mathbf{x}|n, \\theta)\\triangleq\\binom{n}{x_1 \\ldots x_K}\\prod_{j=1}^K\\theta_j^{x_j}\n",
    "$$\n",
    "\n",
    "where $\\theta_j$ is the probability side $j$ shows up, and \n",
    "\n",
    "$$\n",
    "\\binom{n}{x_1\\ldots x_K}\\triangleq \\frac{n!}{x_1! x_2! \\cdots x_K!}\n",
    "$$\n",
    "\n",
    "is the **multinomial coefficient** (the number of ways to divide a set of size $n = \\sum_{k=1}^K x_k$ into subsets with sizes $x_1$ upto $x_K$.\n",
    "\n",
    "Now suppose $n=1$. This is like rolling a $K$-sided dice once, so $\\mathbf{x}$ will be a vector of 0s and 1s (a bit vector), in which only one bit can be turned on. In this case, we can think of $x$ as being a scalar categorical random variable with $K$ states (values), and $\\mathbf{x}$ is its **dummy encoding**, that is, $\\mathbf{x} = [\\mathbb{I}(x=1),\\ldots,\\mathbb{I}(x=K)]$. This is also called a **one-hot encoding**. In this case, the pmf becomes\n",
    "\n",
    "$$\n",
    "\\mathrm{Mu}(\\mathbf{x}|1, \\boldsymbol{\\theta}) = \\prod_{j=1}^K \\theta_j^{\\mathbb{I}(x_j=1)}\n",
    "$$\n",
    "\n",
    "We will use the following notation for this case:\n",
    "$$\n",
    "\\mathrm{Cat}(x|\\boldsymbol{\\theta}) \\triangleq \\mathrm{Mu}(\\mathbf{x}|1, \\boldsymbol{\\theta})\n",
    "$$\n",
    "In other words, if $x\\sim \\mathrm{Cat}(\\boldsymbol{\\theta})$, then $p(x = j|\\boldsymbol{\\theta}) = \\theta_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Poisson Distribution\n",
    "\n",
    "We say that $X \\in \\{0, 1, 2,\\ldots\\}$ has a **Poisson** distribution with parameter $\\lambda > 0$, written $X\\sim \\mathrm{Poi}(\\lambda)$, if its pmf is \n",
    "\n",
    "$$\n",
    "\\mathrm{Poi}(x|\\lambda) = e^{-\\lambda}\\frac{\\lambda^x}{x!}\n",
    "$$\n",
    "\n",
    "The first term is just the normalization constant, required to ensure the distribution sums to 1. The Poisson distribution is often used as a model for counts of rare events like radioactive decay and traffic accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The empirical distribution\n",
    "\n",
    "Given a set of data, $\\mathcal{D} = \\{x_1,\\ldots,x_N\\}$, we define the **empirical distribution**, also called the **empirical measure**, as follows:\n",
    "\n",
    "$$\n",
    "p_{\\mathrm{emp}}(A) \\triangleq \\frac{1}{N}\\sum_{i=1}^N\\delta_{x_k}(A)\n",
    "$$\n",
    "\n",
    "where $\\delta_x(A)$ is the **Dirac measure**, defined by\n",
    "\n",
    "$$\n",
    "\\delta_x(A) = \\left\\{\\begin{array}{lr} 0 &\\mathrm{if}\\, x\\notin A\\\\ 1 & \\mathrm{if}\\,x\\in A\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "In general, we can associate 'weights' with each sample:\n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{i=1}^N w_i\\delta_{x_i}(x)\n",
    "$$\n",
    "\n",
    "where we require $0 \\le w_i\\le 1$ and $\\sum_{i=1}^N w_i=1$. We can think of this as a histogram, which 'spikes' at the data points $x_i$, where $w_i$ determines the height of spike $i$. The distribution assigns 0 probability to any point not in the data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
