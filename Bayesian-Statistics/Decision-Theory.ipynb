{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Decision Theory\n",
    "## Inference and Decision\n",
    "We have broken the classification problem down into two separate stages:\n",
    "* *Inference stage* in which we use training data to learn a model for $p(c_k|\\mathbf{x})$, where $c_k$ is class $k$\n",
    "* *Decision* stage in which whe use the posterior probabilities to make optimal class assignments.\n",
    "\n",
    "An alternative possibility is to solve both problems together and simply learn a function that maps $\\mathbf{x}$ directly to decisions. Such a function is called a **discriminant function**.\n",
    "\n",
    "Altogether, we can identify three distinct approaches to solving decision problems, all with practical applications. In decreasing order of complexity, we have\n",
    "\n",
    "* (a) First solve the inference problem of determining the class-conditional densities $p(\\mathbf{x}|c_k)$ individuall. Also separately infer the prior class probabilities $p(c_k)$. Then use Bayes' theorem in the form\n",
    "\n",
    "$$\n",
    "p(c_k|\\mathbf{x}) = \\frac{p(\\mathbf{x}|c_k)p(c_k)}{p(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "to find the posterior class probabilities $p(c_k|\\mathbf{x})$. As usual, the denominator in Bayes' theorem can be found in terms of quantities appearing in the numerator, because \n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} = \\sum_kp(\\mathbf{x}|c_k)p(c_k)\n",
    "$$\n",
    "\n",
    "Equivalently, we can model the joint distribution $p(\\mathbf{x}, c_k)$ directly and then normalise to obtain the posterior distribution. Having found the posterior probabilities, we use decision theory to determine class membership for each new inpt $\\mathbf{x}$. Approaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as *generative models*, because by sampling from them it is possible to generate synthetic data points in the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) First solve the inference problem of determining the posterior class probabilities $p(c_k|\\mathbf{x})$, and then subsequently use decision theory to assign each new $\\mathbf{x}$ to one of the classes. Approaches that model the posterior probability directly are called *discriminative models*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Find a function $f(\\mathbf{x})$ called a discriminant function, which maps each input $\\mathbf{x}$ directly onto a class label. For instance, in the case of two-class problems, $f(\\cdot)$ might be binary valued and such that $f=0$ represents class $c_1$ and $f=1$ represents class $c_2$. In this case, probabilities play no role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merits and demerits\n",
    "Approach (a) is clearly the most demanding since we need to find the joint distribution over both $\\mathbf{x}$ and $c_k$. For many applications $\\mathbf{x}$ will have high dimensionality, and consequently we need a large training set in order to be able to determine the class conditional densities to reasonable accuracy. (b) is much simpler since we only need to estimate the posterior distribution $p(c_k|\\mathbf{x})$ in order to make predictions. This makes sense since the class conditional probability may contain details that have little effect on the posterior probabilities. (c) is even simpler since we use the training data to find a discriminant function $f(\\mathbf{x})$ that maps each $\\mathbf{x}$ directly onto a class label, thereby combining the inference and decision stages into a single learning problem. However, we no longer have accesses to the posterior probabilities $p(c_k|\\mathbf{x})$. There are many reasons for wanting to compute the posterior probabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimizing Risk\n",
    "Consider a problem in which the elements of the loss matrix are subject to revision from time to time (such as might occur in a financial application). If we know the posterior probabilities, we can trivially revise the minimum risk decision criteria by modifying $\\sum_kL_{kj}p(c_k|\\mathbf{x})$ appropriately. If we have only a discriminant function, then any change to the loss matrix would require that we return to the training data and solve the classification problem afresh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compensating for class priors\n",
    "In a highly imbalanced training dataset, extracting a balanced dataset will allow us to find a more accurate model. However, we then have to compensate for the effects of our modifications to the training data. Suppose we have used such a modified data set and found models for the posterior probabilities are proportional to the prior probabilities, which we can interpret as the fraction of points in each class. We can therefore simply take the posterior probabilities obtained from our artificially balanced data set and first divide by the class fractions in that data set and then multiply by the class fractions in the population to which we wish to apply the model. Finally, we need to normalize to ensure that the new posterior probabilities sum to one. Note that this procedure cannot be applied if we have learnt a discriminant function directly instead of determining posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining models\n",
    "For complex applications, we may wish to break the problem into a number of smaller subproblems each of which can be tackled by a separate module. Rather than combine all of this heterogeneous information into one huge input space, it may be more effective to build one system to interpret multiple separately to interpret the data. As long as each of the two models gives posterior probabilities for the classes, we can combine the outputs systematically using the rules of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(\\mathbf{x}_1, \\mathbf{x}_2|c_k) = p(\\mathbf{x}_1|c_k)p(\\mathbf{x}_2|c_k)\n",
    "$$\n",
    "\n",
    "This is an example of *conditional independency* property, because the independence holds when the distribution is conditioned on the class $C_k$. The posterior probability, given both $x_1$ and $x_2$ data, is the given by \n",
    "\n",
    "\\begin{aligned}\n",
    "p(c_k|\\mathbf{x}_1,\\mathbf{x}_2) & \\propto p(\\mathbf{x}_1\\mathbf{x}_2|c_k)|p(c_k)\\\\\n",
    "& \\propto p(\\mathbf{x}_1|c_k)p(\\mathbf{x}_2|c_k)p(c_k)\\\\\n",
    "& \\frac{p(c_k|\\mathbf{x}_1)p(c_k|\\mathbf{x}_2)}{p(c_k)}\n",
    "\\end{aligned}\n",
    "\n",
    "Thus we need the class prior probabilities $p(c_k)$, which we can estimate from the fractions of data points in each class, and then we need to normalize the resulting posterior probabilities so they sum to one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
